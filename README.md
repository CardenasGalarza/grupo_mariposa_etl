# Pipeline ETL - Grupo Mariposa ğŸ¦‹

**Autor:** Giancarlos Cardenas Galarza  
**Fecha:** Diciembre 2025  
**Prueba TÃ©cnica:** Flujo de datos con PySpark y OmegaConf

---

Pipeline de procesamiento de datos para entregas de productos usando **PySpark** y **OmegaConf**.

## âœ… Requisitos Cumplidos

| # | Requisito | ImplementaciÃ³n |
|---|-----------|----------------|
| 1 | Leer archivo CSV | `read_csv()` en `run_etl.py` |
| 2 | Filtrar por rango de fechas (start_date, end_date) | `filter_by_date_range()` con parÃ¡metros CLI |
| 3 | Salidas particionadas: `data/processed/${fecha_proceso}` | `write_partitioned_output()` con `partitionBy` |
| 4 | OmegaConf para todos los parÃ¡metros desde YAML | `config/config.yaml` |
| 5 | Parametrizable por paÃ­s | `--country GT` en CLI |
| 6 | ConversiÃ³n de unidades: CSÃ—20=unidades | `convert_units()` |
| 7 | Columnas por tipo de entrega (rutina/bonificaciÃ³n) | `add_delivery_type_columns()` |
| 8 | Nombres de columnas estandarizados | `standardize_column_names()` |
| 9 | Detectar/eliminar anomalÃ­as | `remove_anomalies()` |
| 10 | Columnas adicionales con fundamento | `add_extra_columns()` |
| 11 | DocumentaciÃ³n grÃ¡fica y descriptiva | `docs/flujo_datos.md` |

## ğŸ“ Estructura del Proyecto

```
grupo_mariposa_etl/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml              # ConfiguraciÃ³n OmegaConf (REQ 4)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # Punto de entrada alternativo
â”‚   â”œâ”€â”€ etl_pipeline.py          # Pipeline orientado a objetos
â”‚   â”œâ”€â”€ transformations.py       # Funciones de transformaciÃ³n
â”‚   â””â”€â”€ utils.py                 # Utilidades
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â””â”€â”€ global_mobility_data_entrega_productos.csv
â”‚   â””â”€â”€ processed/               # Salida particionada (REQ 3)
â”‚       â”œâ”€â”€ fecha_proceso=20250114/
â”‚       â”œâ”€â”€ fecha_proceso=20250217/
â”‚       â”œâ”€â”€ fecha_proceso=20250314/
â”‚       â”œâ”€â”€ fecha_proceso=20250325/
â”‚       â”œâ”€â”€ fecha_proceso=20250513/
â”‚       â””â”€â”€ fecha_proceso=20250602/
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_etl.py
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ flujo_datos.md           # DocumentaciÃ³n grÃ¡fica (REQ 11)
â”œâ”€â”€ run_etl.py                   # Script principal
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ InstalaciÃ³n

```bash
# Requisitos previos: Python 3.8+, Java 8 o 11

# Instalar dependencias
pip install -r requirements.txt

# En Windows, descargar winutils.exe para Hadoop:
# https://github.com/cdarlint/winutils
```

## âš™ï¸ ConfiguraciÃ³n (config.yaml)

```yaml
# Rango de fechas (REQUISITO 2)
dates:
  start_date: 20250101
  end_date: 20250630

# Filtro de paÃ­s (REQUISITO 5)
filter:
  country: null  # GT, PE, EC, SV, HN, JM o null para todos

# ConversiÃ³n de unidades (REQUISITO 6)
units:
  cs_to_units: 20  # 1 caja = 20 unidades

# Tipos de entrega (REQUISITO 7)
delivery_types:
  routine: ["ZPRE", "ZVE1"]   # Entregas de rutina
  bonus: ["Z04", "Z05"]       # Entregas con bonificaciÃ³n
```

## ğŸ“– Uso

### EjecuciÃ³n BÃ¡sica
```bash
cd grupo_mariposa_etl
python run_etl.py
```

### Con ParÃ¡metros
```bash
# Rango de fechas especÃ­fico
python run_etl.py --start_date 20250101 --end_date 20250331

# Filtrar por paÃ­s
python run_etl.py --country GT

# CombinaciÃ³n de filtros
python run_etl.py --start_date 20250101 --end_date 20250630 --country EC
```

### Todos los ParÃ¡metros CLI
| ParÃ¡metro | DescripciÃ³n | Ejemplo |
|-----------|-------------|---------|
| `--config` | Ruta al YAML | `--config config/config.yaml` |
| `--start_date` | Fecha inicio (YYYYMMDD) | `--start_date 20250101` |
| `--end_date` | Fecha fin (YYYYMMDD) | `--end_date 20250630` |
| `--country` | CÃ³digo de paÃ­s | `--country GT` |

## ğŸ”„ Transformaciones

### REQUISITO 6: ConversiÃ³n de Unidades
```
CS (cajas) Ã— 20 = unidades
ST (stock)  Ã— 1 = unidades
```

### REQUISITO 7: Tipos de Entrega
| Tipo | CategorÃ­a | Columna |
|------|-----------|---------|
| ZPRE, ZVE1 | RUTINA | `es_entrega_rutina = True` |
| Z04, Z05 | BONIFICACION | `es_entrega_bonificacion = True` |
| COBR, otros | - | Excluidos del output |

### REQUISITO 8: Nombres de Columnas Estandarizados
| Original | EstÃ¡ndar |
|----------|----------|
| pais | codigo_pais |
| material | codigo_material |
| precio | precio_original |
| cantidad | cantidad_original |
| unidad | unidad_original |

### REQUISITO 10: Columnas Adicionales
| Columna | Fundamento |
|---------|------------|
| `precio_unitario` | Precio por unidad individual (comparabilidad) |
| `categoria_producto` | ClasificaciÃ³n por tipo de bebida (anÃ¡lisis) |
| `nombre_pais` | Nombre completo (legibilidad) |
| `fecha_formateada` | Tipo Date (ordenamiento) |
| `es_promocion_gratis` | Productos sin costo (anÃ¡lisis promociones) |

## ğŸ“Š Salida

Los datos se guardan en formato Parquet particionados por fecha:

```
data/processed/
â”œâ”€â”€ fecha_proceso=20250114/
â”‚   â””â”€â”€ part-00000.parquet
â”œâ”€â”€ fecha_proceso=20250217/
â”‚   â””â”€â”€ part-00000.parquet
â”œâ”€â”€ fecha_proceso=20250314/
â”‚   â””â”€â”€ part-00000.parquet
â”œâ”€â”€ fecha_proceso=20250325/
â”‚   â””â”€â”€ part-00000.parquet
â”œâ”€â”€ fecha_proceso=20250513/
â”‚   â””â”€â”€ part-00000.parquet
â””â”€â”€ fecha_proceso=20250602/
    â””â”€â”€ part-00000.parquet
```

### Columnas del Dataset Final

```
1. codigo_pais            # CÃ³digo ISO del paÃ­s
2. nombre_pais            # Nombre completo
3. fecha_proceso          # Fecha original (YYYYMMDD)
4. fecha_formateada       # Fecha como tipo Date
5. id_transporte          # ID del transporte
6. id_ruta                # ID de la ruta
7. codigo_material        # CÃ³digo del producto
8. categoria_producto     # CategorÃ­a del producto
9. tipo_entrega           # CÃ³digo original
10. categoria_entrega     # RUTINA o BONIFICACION
11. es_entrega_rutina     # True si ZPRE/ZVE1
12. es_entrega_bonificacion # True si Z04/Z05
13. cantidad_original     # Cantidad original
14. unidad_original       # CS o ST
15. cantidad_unidades     # Cantidad normalizada
16. unidad_estandar       # Siempre "UNIDADES"
17. precio_original       # Precio de la lÃ­nea
18. precio_unitario       # Precio por unidad
19. valor_total           # Valor monetario total
20. es_promocion_gratis   # True si precio = 0
```

## ğŸ§ª Tests

```bash
python -m pytest tests/ -v
```

## ğŸ“ DocumentaciÃ³n Adicional

Ver `docs/flujo_datos.md` para documentaciÃ³n grÃ¡fica del flujo de datos (REQUISITO 11).

## ğŸ‘¨â€ğŸ’» Autor

**Giancarlos Cardenas Galarza**

Desarrollado como prueba tÃ©cnica para **Grupo Mariposa** - Diciembre 2025

---

*Este proyecto fue desarrollado completamente por Giancarlos Cardenas Galarza como parte del proceso de evaluaciÃ³n tÃ©cnica.*
